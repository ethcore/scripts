# .gitlab-ci.yml
# paritytech/scripts
#

stages:
  - build
  - test
  - prod

variables:                         &default-vars
  IMAGE_TAG:                       latest
  REGISTRY_PATH:                   docker.io/paritytech

default:
  cache:                           {}

.build:                            &docker_build
  stage:                           build
  image:                           quay.io/buildah/stable
  rules:
    - if: $IMAGE_NAME == $CI_JOB_NAME
  tags:
    - kubernetes-parity-build

# Push to Dockerhub using buildah
.push_to_docker_hub:               &push_to_docker_hub
  - export IMAGE_DATE_TAG="$CI_COMMIT_SHORT_SHA-$(date +%Y%m%d)"
  - buildah version
  - buildah bud
      --format=docker
      --build-arg VCS_REF="$CI_COMMIT_SHA"
      --build-arg BUILD_DATE="$(date +%Y%m%d)"
      --build-arg REGISTRY_PATH="$REGISTRY_PATH"
      --tag "$REGISTRY_PATH/$IMAGE_NAME:$IMAGE_DATE_TAG"
      --tag "$REGISTRY_PATH/$IMAGE_NAME:$IMAGE_TAG"
      --file "dockerfiles/$IMAGE_NAME/Dockerfile" dockerfiles
  - buildah info
  - echo "$DOCKER_PASSWORD" |
      buildah login --username "$DOCKER_USER" --password-stdin "$REGISTRY_PATH"
  - buildah push --format=v2s2 "$REGISTRY_PATH/$IMAGE_NAME:$IMAGE_DATE_TAG"
  - buildah push --format=v2s2 "$REGISTRY_PATH/$IMAGE_NAME:$IMAGE_TAG"
  - buildah logout "$REGISTRY_PATH"

.push_to_staging:                  &push_to_staging
  - buildah bud
      --format=docker
      --build-arg VCS_REF="$CI_COMMIT_SHA"
      --build-arg BUILD_DATE="$(date +%Y%m%d)"
      --build-arg REGISTRY_PATH="$REGISTRY_PATH"
      --tag "$REGISTRY_PATH/$IMAGE_NAME:staging"
      --file "dockerfiles/$IMAGE_NAME/Dockerfile" dockerfiles
  - echo "$DOCKER_PASSWORD" |
      buildah login --username "$DOCKER_USER" --password-stdin "$REGISTRY_PATH"
  - buildah info
  - buildah push --format=v2s2 "$REGISTRY_PATH/$IMAGE_NAME:staging"
  - buildah logout "$REGISTRY_PATH"

.push_to_production:               &push_to_production
  - export IMAGE_DATE_TAG="$CI_COMMIT_SHORT_SHA-$(date +%Y%m%d)"
  - buildah pull "$REGISTRY_PATH/$IMAGE_NAME:staging"
  - buildah tag "$REGISTRY_PATH/$IMAGE_NAME:staging" "$REGISTRY_PATH/$IMAGE_NAME:production"
  - buildah tag "$REGISTRY_PATH/$IMAGE_NAME:staging" "$REGISTRY_PATH/$IMAGE_NAME:$IMAGE_DATE_TAG"
  - echo "$DOCKER_PASSWORD" |
      buildah login --username "$DOCKER_USER" --password-stdin "$REGISTRY_PATH"
  - buildah info
  - buildah push --format=v2s2 "$REGISTRY_PATH/$IMAGE_NAME:production"
  - buildah push --format=v2s2 "$REGISTRY_PATH/$IMAGE_NAME:$IMAGE_DATE_TAG"
  - buildah logout "$REGISTRY_PATH"

#### stage:                        build

# Build and push to docker hub
base-ci-linux:
  <<:                              *docker_build
  script:
    - *push_to_docker_hub

ci-linux:
  <<:                              *docker_build
  script:
    - *push_to_staging

ink-ci-linux:
  <<:                              *docker_build
  script:
    - *push_to_staging

contracts-ci-linux:
  <<:                              *docker_build
  script:
    - *push_to_staging

sccache-ci-ubuntu:
  <<:                              *docker_build
  script:
    - *push_to_staging

awscli:
  <<:                              *docker_build
  script:
    - *push_to_docker_hub

tools:
  <<:                              *docker_build
  script:
    - *push_to_docker_hub

query-exporter:
  <<:                              *docker_build
  script:
    - *push_to_docker_hub

redis-exporter:
  <<:                              *docker_build
  script:
    - *push_to_docker_hub

# build k8s on top of node 12-alpine
chaostools:
  <<:                              *docker_build
  variables:
    <<:                            *default-vars
    # https://github.com/kubernetes/kubernetes/releases
    BUILD_KUBE_VERSION:            "1.18.2"
  script:
    - |
      cat <<-EOT
      |
      | # build of chaostools image>
      |
      | KUBE_VERSION = $BUILD_KUBE_VERSION
      |
      EOT
    - buildah bud
      --format=docker
      --build-arg VCS_REF="$CI_COMMIT_SHA"
      --build-arg BUILD_DATE="$(date -u '+%Y-%m-%dT%H:%M:%SZ')"
      --build-arg REGISTRY_PATH="$REGISTRY_PATH"
      --build-arg KUBE_VERSION="$BUILD_KUBE_VERSION"
      --tag "$REGISTRY_PATH/$IMAGE_NAME:$IMAGE_TAG"
      --file "dockerfiles/$IMAGE_NAME/Dockerfile" dockerfiles
    # Push to Dockerhub
    - echo "$DOCKER_PASSWORD" |
        buildah login --username "$DOCKER_USER" --password-stdin "$REGISTRY_PATH"
    - buildah info
    - buildah push --format=v2s2 "$REGISTRY_PATH/$IMAGE_NAME:$IMAGE_TAG"
    - buildah logout "$REGISTRY_PATH"

# special case as version tags are introduced
kubetools:
  <<:                              *docker_build
  variables:
    <<:                            *default-vars
    # https://github.com/kubernetes/kubernetes/releases
    BUILD_KUBE_VERSION:            "1.18.2"
    # https://github.com/kubernetes/helm/releases
    # will be overwritten by the global variable at
    # https://gitlab.parity.io/groups/parity/-/settings/ci_cd
    BUILD_HELM_VERSION:            "2.16.11"
  script:
    - |
      cat <<-EOT
      |
      | # build of kubetools image
      |
      | KUBE_VERSION = $BUILD_KUBE_VERSION
      | HELM_VERSION = $BUILD_HELM_VERSION
      |
      EOT
    - buildah bud
      --format=docker
      --build-arg VCS_REF="$CI_COMMIT_SHA"
      --build-arg BUILD_DATE="$(date -u '+%Y-%m-%dT%H:%M:%SZ')"
      --build-arg REGISTRY_PATH="$REGISTRY_PATH"
      --build-arg KUBE_VERSION="$BUILD_KUBE_VERSION"
      --build-arg HELM_VERSION="$BUILD_HELM_VERSION"
      --tag "$REGISTRY_PATH/$IMAGE_NAME:$IMAGE_TAG"
      --tag "$REGISTRY_PATH/$IMAGE_NAME:$BUILD_HELM_VERSION"
      --file "dockerfiles/$IMAGE_NAME/Dockerfile" dockerfiles
    # Push to Dockerhub
    - echo "$DOCKER_PASSWORD" |
        buildah login --username "$DOCKER_USER" --password-stdin "$REGISTRY_PATH"
    - buildah info
    - buildah push --format=v2s2 "$REGISTRY_PATH/$IMAGE_NAME:$IMAGE_TAG"
    - buildah push --format=v2s2 "$REGISTRY_PATH/$IMAGE_NAME:$BUILD_HELM_VERSION"
    - buildah logout "$REGISTRY_PATH"


terraform:
  <<:                              *docker_build
  variables:
    <<:                            *default-vars
    # https://releases.hashicorp.com/terraform/
    TERRAFORM_VERSION:             "0.13.5"
  script:
    - |
      cat <<-EOT
      |
      | # build of terraform image
      |
      | TERRAFORM_VERSION = $TERRAFORM_VERSION
      |
      EOT
    - buildah bud
      --format=docker
      --build-arg VCS_REF="$CI_COMMIT_SHA"
      --build-arg BUILD_DATE="$(date -u '+%Y-%m-%dT%H:%M:%SZ')"
      --build-arg REGISTRY_PATH="$REGISTRY_PATH"
      --build-arg TERRAFORM_VERSION="$TERRAFORM_VERSION"
      --tag "$REGISTRY_PATH/$IMAGE_NAME:$IMAGE_TAG"
      --tag "$REGISTRY_PATH/$IMAGE_NAME:$TERRAFORM_VERSION"
      --file "dockerfiles/$IMAGE_NAME/Dockerfile" dockerfiles
    # Push to Dockerhub
    - echo "$DOCKER_PASSWORD" |
        buildah login --username "$DOCKER_USER" --password-stdin "$REGISTRY_PATH"
    - buildah info
    - buildah push --format=v2s2 "$REGISTRY_PATH/$IMAGE_NAME:$IMAGE_TAG"
    - buildah push --format=v2s2 "$REGISTRY_PATH/$IMAGE_NAME:$TERRAFORM_VERSION"
    - buildah logout "$REGISTRY_PATH"

#### stage:                        test

# triggers on $IMAGE_NAME
# in order to be scanned, EVERY docker build HAS to have $REGISTRY_PATH/$IMAGE_NAME:$IMAGE_TAG
# container_scanning:
#   # Template does not work, had to override its config from
#   # https://gitlab.com/gitlab-org/gitlab/blob/master/lib/gitlab/ci/templates/Security/Container-Scanning.gitlab-ci.yml
#   # these settings are from the template 
#   stage:                           test
#   image:                           $SECURE_ANALYZERS_PREFIX/klar:$CS_MAJOR_VERSION
#   services:
#     - name:                        $CLAIR_DB_IMAGE
#       alias:                       clair-vulnerabilities-db
#   allow_failure:                   true
#   script:
#     - /analyzer run
#   artifacts:
#     reports:
#       container_scanning:          gl-container-scanning-report.json
#   variables:
#     SECURE_ANALYZERS_PREFIX:       "registry.gitlab.com/gitlab-org/security-products/analyzers"
#     CS_MAJOR_VERSION:              2
#     CLAIR_DB_IMAGE_TAG:            "latest"
#     CLAIR_DB_IMAGE:                "$SECURE_ANALYZERS_PREFIX/clair-vulnerabilities-db:$CLAIR_DB_IMAGE_TAG"
#   # these are our overrides
#     <<:                            *default-vars
#     GIT_STRATEGY:                  fetch
#     CI_APPLICATION_REPOSITORY:     $REGISTRY_PATH/$IMAGE_NAME
#     CI_APPLICATION_TAG:            $IMAGE_TAG # OR $IMAGE_DATE_TAG
#     DOCKERFILE_PATH:               dockerfiles/$IMAGE_NAME/Dockerfile
#   rules:
#     - if: $IMAGE_NAME
#   tags:
#     - kubernetes-parity-build

container_scanning:
  image:                           docker.io/aquasec/trivy:latest
  script:
    - cd /
    # cache cleanup is needed when scanning images with the same tags, it does not remove the database
    - time trivy image --clear-cache
    # update vulnerabilities db
    - time trivy --download-db-only --no-progress --cache-dir .trivycache/
    # Build report
    # - time trivy --exit-code 0 --cache-dir .trivycache/ --no-progress --format template --template "/contrib/gitlab.tpl" -o gl-container-scanning-report.json "$REGISTRY_PATH/$IMAGE_NAME"
    - pwd
    - ls /
    - time trivy --exit-code 0 --cache-dir .trivycache/ --no-progress --format template --template "@contrib/gitlab.tpl" --output gl-container-scanning-report.json "$REGISTRY_PATH/$IMAGE_NAME"
    # debug
    - cat gl-container-scanning-report.json
    # Print report
    - time trivy --exit-code 0 --cache-dir .trivycache/ --no-progress "$REGISTRY_PATH/$IMAGE_NAME"
    # Fail on high and critical vulnerabilities
    - time trivy --exit-code 1 --cache-dir .trivycache/ --severity CRITICAL --no-progress "$REGISTRY_PATH/$IMAGE_NAME"
  cache:
    paths:
      - .trivycache/
  artifacts:
    reports:
      # there's something with this template
      container_scanning:          gl-container-scanning-report.json
  rules:
    - if: $IMAGE_NAME
  allow_failure:                   true
  tags:
    - kubernetes-parity-build
  

# official job suggested in trivy doc
# container_scanning2:
#   stage: test
#   image: docker:stable
#   services:
#     - name: docker:dind
#       entrypoint: ["env", "-u", "DOCKER_HOST"]
#       command: ["dockerd-entrypoint.sh"]
#   variables:
#     DOCKER_HOST: tcp://docker:2375/
#     DOCKER_DRIVER: overlay2
#     # See https://github.com/docker-library/docker/pull/166
#     DOCKER_TLS_CERTDIR: ""
#   before_script:
#     - export TRIVY_VERSION=$(wget -qO - "https://api.github.com/repos/aquasecurity/trivy/releases/latest" | grep '"tag_name":' | sed -E 's/.*"v([^"]+)".*/\1/')
#     - echo $TRIVY_VERSION
#     - wget --no-verbose https://github.com/aquasecurity/trivy/releases/download/v${TRIVY_VERSION}/trivy_${TRIVY_VERSION}_Linux-64bit.tar.gz -O - | tar -zxvf -
#   allow_failure: true
#   script:
#     # Build report
#     - ./trivy --exit-code 0 --cache-dir .trivycache/ --no-progress --format template --template "@contrib/gitlab.tpl" -o gl-container-scanning-report.json "$REGISTRY_PATH/$IMAGE_NAME"
#     # Print report
#     - ./trivy --exit-code 0 --cache-dir .trivycache/ --no-progress --severity HIGH "$REGISTRY_PATH/$IMAGE_NAME"
#     # Fail on high and critical vulnerabilities
#     - ./trivy --exit-code 1 --cache-dir .trivycache/ --severity CRITICAL --no-progress "$REGISTRY_PATH/$IMAGE_NAME"
#   cache:
#     paths:
#       - .trivycache/
#   artifacts:
#     reports:
#       container_scanning: gl-container-scanning-report.json
#   rules:
#     - if: $IMAGE_NAME
#   tags:
#     - kubernetes-parity-build

# concept of using trivy as a binary, updating and running in the $IMAGE_NAME
# downside is it uses tar and curl and we'd like to get rid of them in some images
# upside is it uses images from the docker cache
# container_scanning3:
#   stage:                           test
#   image:                           $REGISTRY_PATH/$IMAGE_NAME # check if can be tagged
#   allow_failure:                   true
#   before_script:
#     - export LOCAL_TRIVY=$(/ci-cache/trivy/trivy --version | grep -Po "(?<=^Version:).*") || (
#         echo "No local trivy, downloading."
#       )
#     - export LATEST_TRIVY=$(
#         curl -sS "https://api.github.com/repos/aquasecurity/trivy/releases/latest" |
#         grep '"tag_name":' |
#         sed -E 's/.*"v([^"]+)".*/\1/'
#       )
#     - mkdir -p /ci-cache/trivy/cache
#     # compares local vs latest version, updates if newer
#     - if [ $LOCAL_TRIVY != $LATEST_TRIVY ]; then
#         curl -sS -L "https://github.com/aquasecurity/trivy/releases/download/v${LATEST_TRIVY}/trivy_${LATEST_TRIVY}_Linux-64bit.tar.gz"
#           --output /tmp/trivy.tar.gz;
#         cd /tmp;
#         tar -xzf trivy.tar.gz trivy;
#         mv trivy /ci-cache/trivy/;
#       fi
#   script:
#     - /ci-cache/trivy/trivy --download-db-only --cache-dir /ci-cache/trivy/cache
#     # cache cleanup is needed when scanning images with the same tags, it does not remove the database
#     - /ci-cache/trivy/trivy image --clear-cache
#     # Build report
#     - /ci-cache/trivy/trivy --exit-code 0 --cache-dir /ci-cache/trivy/cache --no-progress --format template --template "@contrib/gitlab.tpl" -o gl-container-scanning-report.json filesystem /
#     # Print report
#     - /ci-cache/trivy/trivy --exit-code 0 --cache-dir /ci-cache/trivy/cache --no-progress --severity HIGH filesystem /
#     # Fail on high and critical vulnerabilities
#     - /ci-cache/trivy/trivy --exit-code 1 --cache-dir /ci-cache/trivy/cache --severity CRITICAL --no-progress filesystem /
#   artifacts:
#     reports:
#       container_scanning: gl-container-scanning-report.json
#   rules:
#     - if: $IMAGE_NAME
#   tags:
#     - linux-docker

ci-linux-test:
  stage:                           test
  image:                           $REGISTRY_PATH/$IMAGE_NAME:staging
  interruptible:                   true
  rules:
    - if: $IMAGE_NAME == "ci-linux"
  variables:
    <<:                            *default-vars
    GIT_STRATEGY:                  none
    RUSTFLAGS:                     "-Cdebug-assertions=y"
    WASM_BUILD_NO_COLOR:           1
  before_script:
    - rustup show
    - cargo --version
    - sccache -s
  script:
    - git clone https://github.com/paritytech/substrate .
    # test-linux-stable:
    - time cargo test --workspace --locked --release --verbose --features runtime-benchmarks --manifest-path bin/node/cli/Cargo.toml
    # check-web-wasm:
    - time cargo build --target=wasm32-unknown-unknown -p sp-io
    - time cargo build --target=wasm32-unknown-unknown -p sp-runtime
    - time cargo build --target=wasm32-unknown-unknown -p sp-std
    - time cargo build --target=wasm32-unknown-unknown -p sc-consensus-aura
    - time cargo build --target=wasm32-unknown-unknown -p sc-consensus-babe
    - time cargo build --target=wasm32-unknown-unknown -p sp-consensus
    - time cargo build --target=wasm32-unknown-unknown -p sc-telemetry
    - time cargo +nightly build --manifest-path=bin/node/cli/Cargo.toml --no-default-features --features browser --target=wasm32-unknown-unknown -Z features=itarget
  tags:
    - linux-docker

ink-ci-linux-test:
  stage:                           test
  variables:
    CI_IMAGE:                      "paritytech/ink-ci-linux:staging"
  rules:
    - if: $IMAGE_NAME == "ink-ci-linux"
  trigger:
    project:                       parity/ink
    branch:                        master
    strategy:                      depend

contracts-ci-linux-test:
  stage:                           test
  variables:
    CI_IMAGE:                      "paritytech/contracts-ci-linux:staging"
  rules:
    - if: $IMAGE_NAME == "contracts-ci-linux"
  trigger:
    project:                       parity/cargo-contract
    branch:                        master
    strategy:                      depend

sccache-ci-ubuntu-test:
  stage:                           test
  variables:
    CI_IMAGE:                      "paritytech/sccache-ci-ubuntu:staging"
  rules:
    - if: $IMAGE_NAME == "sccache-ci-ubuntu"
  trigger:
    project:                       parity/sccache
    branch:                        master
    strategy:                      depend

#### stage:                        prod

ci-linux-production:
  stage:                           prod
  image:                           quay.io/buildah/stable
  rules:
    - if: $IMAGE_NAME == "ci-linux"
  script:
    - *push_to_production
  tags:
    - kubernetes-parity-build

ink-ci-linux-production:           &push-after-triggered-pipeline
  stage:                           prod
  image:                           quay.io/buildah/stable
  needs:
    - job:                         ink-ci-linux-test
      artifacts:                   false
  rules:
    - if: $IMAGE_NAME == "ink-ci-linux"
  script:
    - *push_to_production
  tags:
    - kubernetes-parity-build

contracts-ci-linux-production:
  <<:                              *push-after-triggered-pipeline
  needs:
    - job:                         contracts-ci-linux-test
      artifacts:                   false
  rules:
    - if: $IMAGE_NAME == "contracts-ci-linux"
  

sccache-ci-ubuntu-production:
  <<:                              *push-after-triggered-pipeline
  needs:
    - job:                         sccache-ci-ubuntu-test
      artifacts:                   false
  rules:
    - if: $IMAGE_NAME == "sccache-ci-ubuntu"
